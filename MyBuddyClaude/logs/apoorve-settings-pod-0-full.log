Starting OPTIMIZED PyTorch AllReduce Benchmark on pod pytorch-benchmark-opt-0
+ echo 'Starting OPTIMIZED PyTorch AllReduce Benchmark on pod pytorch-benchmark-opt-0'
+ export NODE_RANK=0
+ NODE_RANK=0
+ export NNODES=2
+ NNODES=2
+ export NPROC_PER_NODE=4
+ NPROC_PER_NODE=4
+ export MASTER_PORT=29501
+ MASTER_PORT=29501
+ '[' pytorch-benchmark-opt-0 = pytorch-benchmark-opt-0 ']'
+ export MASTER_ADDR=10.129.2.187
+ MASTER_ADDR=10.129.2.187
+ echo 'I am the master node (node_rank 0)'
+ echo 'NODE_RANK=0, NNODES=2, NPROC_PER_NODE=4'
+ echo 'MASTER_ADDR=10.129.2.187, MASTER_PORT=29501'
+ echo 'Total GPUs: 8'
+ echo '=== GPU Information ==='
+ nvidia-smi --query-gpu=index,name,memory.total --format=csv
I am the master node (node_rank 0)
NODE_RANK=0, NNODES=2, NPROC_PER_NODE=4
MASTER_ADDR=10.129.2.187, MASTER_PORT=29501
Total GPUs: 8
=== GPU Information ===
index, name, memory.total [MiB]
0, NVIDIA H100 80GB HBM3, 81559 MiB
1, NVIDIA H100 80GB HBM3, 81559 MiB
2, NVIDIA H100 80GB HBM3, 81559 MiB
3, NVIDIA H100 80GB HBM3, 81559 MiB
=== RDMA Devices ===
+ echo '=== RDMA Devices ==='
+ ls -la /dev/infiniband/
total 0
drwxr-xr-x. 2 root root      220 Jan 29 16:38 .
drwxr-xr-x. 6 root root      540 Jan 29 16:38 ..
crw-rw-rw-. 1 root root  10, 123 Jan 29 16:38 rdma_cm
crw-rw-rw-. 1 root root 231,  10 Jan 29 16:38 umad10
crw-rw-rw-. 1 root root 231,  11 Jan 29 16:38 umad11
crw-rw-rw-. 1 root root 231,   6 Jan 29 16:38 umad6
crw-rw-rw-. 1 root root 231,   7 Jan 29 16:38 umad7
crw-rw-rw-. 1 root root 231, 202 Jan 29 16:38 uverbs10
crw-rw-rw-. 1 root root 231, 203 Jan 29 16:38 uverbs11
crw-rw-rw-. 1 root root 231, 198 Jan 29 16:38 uverbs6
crw-rw-rw-. 1 root root 231, 199 Jan 29 16:38 uverbs7
=== SR-IOV Network Interfaces ===
+ echo '=== SR-IOV Network Interfaces ==='
+ for iface in net1 net2 net3 net4
+ '[' -e /sys/class/net/net1 ']'
++ cat /sys/class/net/net1/address
++ cat /sys/class/net/net1/mtu
net1: 66:19:7a:ca:0c:3a MTU=9000
+ echo 'net1: 66:19:7a:ca:0c:3a MTU=9000'
+ for iface in net1 net2 net3 net4
+ '[' -e /sys/class/net/net2 ']'
++ cat /sys/class/net/net2/address
++ cat /sys/class/net/net2/mtu
net2: e2:aa:4a:59:84:f4 MTU=9000
+ echo 'net2: e2:aa:4a:59:84:f4 MTU=9000'
+ for iface in net1 net2 net3 net4
+ '[' -e /sys/class/net/net3 ']'
++ cat /sys/class/net/net3/address
++ cat /sys/class/net/net3/mtu
net3: 6a:10:57:83:44:23 MTU=9000
+ echo 'net3: 6a:10:57:83:44:23 MTU=9000'
+ for iface in net1 net2 net3 net4
+ '[' -e /sys/class/net/net4 ']'
++ cat /sys/class/net/net4/address
++ cat /sys/class/net/net4/mtu
net4: 26:92:ee:e7:ad:9d MTU=9000
+ echo 'net4: 26:92:ee:e7:ad:9d MTU=9000'
=== Optimized NCCL Environment ===
+ echo '=== Optimized NCCL Environment ==='
+ env
+ grep NCCL
+ sort
AWS_OFI_NCCL_VERSION=1.12.1
NCCL_ALGO=Ring
NCCL_BUFFSIZE=67108864
NCCL_CROSS_NIC=2
NCCL_DEBUG=INFO
NCCL_DEBUG_SUBSYS=INIT,NET
NCCL_DMABUF_ENABLE=0
NCCL_IB_AR_THRESHOLD=8192
NCCL_IB_DISABLE=0
NCCL_IB_GID_INDEX=3
NCCL_IB_HCA=mlx5_6,mlx5_7,mlx5_10,mlx5_11
NCCL_IB_MERGE_NICS=0
NCCL_IB_PCI_RELAXED_ORDERING=1
NCCL_IB_QPS_PER_CONNECTION=2
NCCL_IB_RETRY_CNT=7
NCCL_IB_SL=0
NCCL_IB_TC=106
NCCL_IB_TIMEOUT=22
NCCL_IGNORE_CPU_AFFINITY=1
NCCL_LL_THRESHOLD=0
NCCL_MAX_NCHANNELS=16
NCCL_MIN_NCHANNELS=8
NCCL_NET_GDR_LEVEL=1
NCCL_NET_GDR_READ=1
NCCL_NET_OVERHEAD=0
NCCL_NET_SHARED_BUFFERS=1
NCCL_NSOCKS_PERTHREAD=8
NCCL_NTHREADS=640
NCCL_NVLS_ENABLE=0
NCCL_PROTO=Simple
NCCL_SOCKET_FAMILY=4
NCCL_SOCKET_IFNAME=net1,net2,net3,net4
NCCL_SOCKET_NTHREADS=8
NCCL_TOPO_FILE=
NCCL_TREE_THRESHOLD=0
NCCL_VERSION=2.23.4
Waiting for all pods to be ready...
+ echo 'Waiting for all pods to be ready...'
+ sleep 10
=== Starting OPTIMIZED PyTorch Distributed Benchmark ===
+ echo '=== Starting OPTIMIZED PyTorch Distributed Benchmark ==='
+ torchrun --nnodes=2 --nproc_per_node=4 --node_rank=0 --master_addr=10.129.2.187 --master_port=29501 --rdzv_backend=c10d --rdzv_endpoint=10.129.2.187:29501 /benchmark/allreduce-loop.py --multiplier 1
W0129 16:38:23.248000 39 torch/distributed/run.py:793] 
W0129 16:38:23.248000 39 torch/distributed/run.py:793] *****************************************
W0129 16:38:23.248000 39 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0129 16:38:23.248000 39 torch/distributed/run.py:793] *****************************************
NCCL version :  (2, 23, 4)
 size(MB)   tavg(usec)    tmin(usec)    tmax(usec)  avgbw(GB/sec)  maxbw(GB/sec)  minbw(GB/sec)
pytorch-benchmark-opt-0:107:107 [0] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:107:107 [0] NCCL INFO cudaDriverVersion 13000
pytorch-benchmark-opt-0:107:107 [0] NCCL INFO NCCL version 2.23.4+cuda12.6
pytorch-benchmark-opt-0:108:108 [1] NCCL INFO cudaDriverVersion 13000
pytorch-benchmark-opt-0:108:108 [1] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:108:108 [1] NCCL INFO NCCL version 2.23.4+cuda12.6
pytorch-benchmark-opt-0:109:109 [2] NCCL INFO cudaDriverVersion 13000
pytorch-benchmark-opt-0:109:109 [2] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:110:110 [3] NCCL INFO cudaDriverVersion 13000
pytorch-benchmark-opt-0:110:110 [3] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:109:109 [2] NCCL INFO NCCL version 2.23.4+cuda12.6
pytorch-benchmark-opt-0:110:110 [3] NCCL INFO NCCL version 2.23.4+cuda12.6
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO P2P plugin v8 IBext_v8
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO P2P plugin v8 IBext_v8
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO P2P plugin v8 IBext_v8
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO P2P plugin v8 IBext_v8
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NCCL_SOCKET_IFNAME set to net1,net2,net3,net4
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : Using [0]mlx5_6:1/RoCE [1]mlx5_7:1/RoCE [2]mlx5_10:1/RoCE [3]mlx5_11:1/RoCE [RO]; OOB net1:10.0.103.2<0>
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Using network IBext_v8
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : Using [0]mlx5_6:1/RoCE [1]mlx5_7:1/RoCE [2]mlx5_10:1/RoCE [3]mlx5_11:1/RoCE [RO]; OOB net1:10.0.103.2<0>
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : Using [0]mlx5_6:1/RoCE [1]mlx5_7:1/RoCE [2]mlx5_10:1/RoCE [3]mlx5_11:1/RoCE [RO]; OOB net1:10.0.103.2<0>
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO Using network IBext_v8
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO Using network IBext_v8
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : Using [0]mlx5_6:1/RoCE [1]mlx5_7:1/RoCE [2]mlx5_10:1/RoCE [3]mlx5_11:1/RoCE [RO]; OOB net1:10.0.103.2<0>
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO Using network IBext_v8
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO ncclCommInitRankConfig comm 0x8bb8b90 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 6000 commId 0x82e7de691c6736a - Init START
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO ncclCommInitRankConfig comm 0x8a71100 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c6000 commId 0x82e7de691c6736a - Init START
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO ncclCommInitRankConfig comm 0x8bcf130 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 26000 commId 0x82e7de691c6736a - Init START
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO ncclCommInitRankConfig comm 0x9218870 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId a6000 commId 0x82e7de691c6736a - Init START

pytorch-benchmark-opt-0:110:135 [3] graph/xml.cc:375 NCCL WARN Could not open XML topology file  : No such file or directory

pytorch-benchmark-opt-0:109:134 [2] graph/xml.cc:375 NCCL WARN Could not open XML topology file  : No such file or directory

pytorch-benchmark-opt-0:107:132 [0] graph/xml.cc:375 NCCL WARN Could not open XML topology file  : No such file or directory

pytorch-benchmark-opt-0:108:133 [1] graph/xml.cc:375 NCCL WARN Could not open XML topology file  : No such file or directory
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 0 'mlx5_6'
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 0 'mlx5_6'
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 1 'mlx5_7'
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 1 'mlx5_7'
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 0 'mlx5_6'
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 2 'mlx5_10'
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 1 'mlx5_7'
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 2 'mlx5_10'
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 3 'mlx5_11'
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 3 'mlx5_11'
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 2 'mlx5_10'
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 3 'mlx5_11'
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 0 'mlx5_6'
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 1 'mlx5_7
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 1 'mlx5_7'
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 2 'mlx5_10
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 2 'mlx5_10'
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NET/IBext_v8 : GPU Direct RDMA Enabled for HCA 3 'mlx5_11'
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PIX
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PIX
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PIX
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PIX
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,00000000,0000ffff,ffffffff
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 0 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 1 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 2 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO GPU Direct RDMA Disabled for GPU c6000 / HCA 3 (distance 4 > 3)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ffffffff,00000000,0000ffff,ffffffff
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO comm 0x8bcf130 rank 1 nRanks 8 nNodes 2 localRanks 4 localRank 1 MNNVL 0
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO comm 0x8a71100 rank 3 nRanks 8 nNodes 2 localRanks 4 localRank 3 MNNVL 0
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO comm 0x9218870 rank 2 nRanks 8 nNodes 2 localRanks 4 localRank 2 MNNVL 0
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 2/-1/-1->3->0 [2] 0/-1/-1->3->2 [3] 2/7/-1->3->-1 [4] -1/-1/-1->3->2 [5] 2/-1/-1->3->0 [6] 0/-1/-1->3->2 [7] 2/-1/-1->3->7
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO P2P Chunksize set to 131072
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 0/5/-1->1->-1 [2] -1/-1/-1->1->0 [3] 0/-1/-1->1->2 [4] 2/-1/-1->1->0 [5] 0/-1/-1->1->5 [6] -1/-1/-1->1->0 [7] 0/-1/-1->1->2
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO P2P Chunksize set to 131072
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] -1/-1/-1->2->3 [2] 3/6/-1->2->-1 [3] 1/-1/-1->2->3 [4] 3/-1/-1->2->1 [5] -1/-1/-1->2->3 [6] 3/-1/-1->2->6 [7] 1/-1/-1->2->3
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO P2P Chunksize set to 131072
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO comm 0x8bb8b90 rank 0 nRanks 8 nNodes 2 localRanks 4 localRank 0 MNNVL 0
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 00/08 : 0 2 6 4 7 5 1 3
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 01/08 : 0 3 1 5 7 4 6 2
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 02/08 : 0 2 6 4 7 5 1 3
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 03/08 : 0 3 1 5 7 4 6 2
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 04/08 : 0 2 6 4 7 5 1 3
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 05/08 : 0 3 1 5 7 4 6 2
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 06/08 : 0 2 6 4 7 5 1 3
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Channel 07/08 : 0 3 1 5 7 4 6 2
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 3/-1/-1->0->1 [2] 1/-1/-1->0->3 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->4 [5] 3/-1/-1->0->1 [6] 1/-1/-1->0->3 [7] -1/-1/-1->0->1
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO P2P Chunksize set to 131072
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO [Proxy Service] Device 3 CPU core 94
pytorch-benchmark-opt-0:109:156 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 172
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO [Proxy Service] Device 1 CPU core 41
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO [Proxy Service] Device 2 CPU core 62
pytorch-benchmark-opt-0:108:155 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 113
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
pytorch-benchmark-opt-0:110:157 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 150
pytorch-benchmark-opt-0:107:159 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 34

pytorch-benchmark-opt-0:110:135 [3] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:110:135 [3] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:110:135 [3] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:109:134 [2] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512

pytorch-benchmark-opt-0:109:134 [2] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer

pytorch-benchmark-opt-0:109:134 [2] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer

pytorch-benchmark-opt-0:108:133 [1] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:108:133 [1] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:108:133 [1] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer

pytorch-benchmark-opt-0:107:132 [0] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:107:132 [0] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).

pytorch-benchmark-opt-0:107:132 [0] graph/tuning.cc:22 NCCL WARN Invalid NCCL_NTHREADS 640 (maximum 512).
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO ncclCommInitRankConfig comm 0x8a71100 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c6000 commId 0x82e7de691c6736a - Init COMPLETE
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO ncclCommInitRankConfig comm 0x9218870 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId a6000 commId 0x82e7de691c6736a - Init COMPLETE
pytorch-benchmark-opt-0:110:135 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 8 total 2.28 (kernels 0.25, alloc 1.78, bootstrap 0.02, allgathers 0.02, topo 0.05, graphs 0.13, connections 0.02, rest 0.00)
pytorch-benchmark-opt-0:109:134 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 8 total 2.28 (kernels 0.26, alloc 1.79, bootstrap 0.00, allgathers 0.02, topo 0.05, graphs 0.13, connections 0.02, rest 0.00)
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO ncclCommInitRankConfig comm 0x8bcf130 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 26000 commId 0x82e7de691c6736a - Init COMPLETE
pytorch-benchmark-opt-0:108:133 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 8 total 2.28 (kernels 0.25, alloc 1.79, bootstrap 0.01, allgathers 0.02, topo 0.05, graphs 0.13, connections 0.02, rest 0.00)
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO ncclCommInitRankConfig comm 0x8bb8b90 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 6000 commId 0x82e7de691c6736a - Init COMPLETE
pytorch-benchmark-opt-0:107:132 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 8 total 2.30 (kernels 0.25, alloc 1.72, bootstrap 0.09, allgathers 0.01, topo 0.05, graphs 0.15, connections 0.02, rest 0.00)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 0 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68004f40
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 0 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080004f40
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 00/0 : 0[0] -> 2[2] via P2P/CUMEM
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 1 from local rank 2, transport 0
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 1 from local rank 3, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68004fb8
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080004fb8
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 00/0 : 1[1] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8004f40
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 2 from local rank 3, transport 0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 0 from local rank 1, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005030
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 2 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005030
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64004f40
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 1 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8004fb8
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 3 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f00800050a8
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 3 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d680050a8
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 04/0 : 0[0] -> 2[2] via P2P/CUMEM
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 02/0 : 1[1] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 2 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005030
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 1 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64004fb8
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 06/0 : 0[0] -> 2[2] via P2P/CUMEM
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 04/0 : 1[1] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 3 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a80050a8
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 2 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005030
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 06/0 : 1[1] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 3 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf640050a8
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 01/0 : 0[0] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 4 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005120
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 5 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005198
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 4 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005120
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 6 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005210
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 5 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005198
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Channel 07/0 : 0[0] -> 3[3] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 7 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005288
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 6 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005210
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy recv connection 7 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005288
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 8 from local rank 0, transport 0
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 8 from local rank 3, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005300
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005300
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 9 from local rank 3, transport 0
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 9 from local rank 0, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005378
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005378
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 04/0 : 3[3] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 10 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a80053f0
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 10 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f00800053f0
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 11 from local rank 0, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005468
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 11 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005468
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 01/0 : 3[3] -> 1[1] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 12 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a80054e0
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 12 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f00800054e0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/CUMEM
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 13 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005558
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 13 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005558
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/CUMEM
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 14 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a80055d0
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 14 from local rank 3, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f00800055d0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/CUMEM
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 15 from local rank 3, transport 0
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy recv connection 15 from local rank 0, transport 0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005648
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005648
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 4 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005120
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:164 [2] NCCL INFO [Proxy Progress] Device 2 CPU core 168
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 01/0 : 6[2] -> 2[2] [receive] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 5 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005198
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 03/0 : 6[2] -> 2[2] [receive] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 6 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005210
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 05/0 : 6[2] -> 2[2] [receive] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy recv connection 7 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005288
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 07/0 : 6[2] -> 2[2] [receive] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 8 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005300
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 00/0 : 2[2] -> 6[2] [send] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 9 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005378
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 02/0 : 2[2] -> 6[2] [send] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 10 from local rank 2, transport 2
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 4 from local rank 1, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d680053f0
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 04/0 : 2[2] -> 6[2] [send] via NET/IBext_v8/3
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO GPU Direct RDMA Disabled for GPU a6000 / HCA 3 (distance 6 > 3)
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005120
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 11 from local rank 2, transport 2
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005468
pytorch-benchmark-opt-0:108:165 [1] NCCL INFO [Proxy Progress] Device 1 CPU core 40
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 3 'mlx5_11
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [send] via NET/IBext_v8/3
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 00/0 : 5[1] -> 1[1] [receive] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 5 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005198
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 02/0 : 5[1] -> 1[1] [receive] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 6 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005210
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 04/0 : 5[1] -> 1[1] [receive] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 7 from local rank 1, transport 2
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 12 from local rank 2, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005288
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d680054e0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 06/0 : 5[1] -> 1[1] [receive] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 8 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005300
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 01/0 : 1[1] -> 5[1] [send] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 9 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005378
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 03/0 : 1[1] -> 5[1] [send] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 13 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005558
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 10 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf640053f0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 05/0 : 1[1] -> 5[1] [send] via NET/IBext_v8/0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 26000 / HCA 0 (distance 6 > 3)
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 11 from local rank 1, transport 2
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005468
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (nvidia-peermem) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB : GPU Direct RDMA (DMABUF) enabled for HCA 0 'mlx5_6
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 05/0 : 2[2] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Channel 07/0 : 1[1] -> 5[1] [send] via NET/IBext_v8/0
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 14 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d680055d0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 15 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d68005648
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 12 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf640054e0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 13 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005558
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 16 from local rank 2, transport 0
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO New proxy send connection 16 from local rank 0, transport 0
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a80056c0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 2 -> connection 0x7f1d680056c0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 14 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf640055d0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy recv connection 15 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf64005648
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 16 from local rank 1, transport 0
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO New proxy send connection 16 from local rank 3, transport 0
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f00800056c0
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 1 -> connection 0x7fcf640056c0
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6123 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x40f00 fifoLkey=0x40f00
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6124 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x40f00 fifoLkey=0x40f00
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO New proxy send connection 17 from local rank 0, transport 0
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO New proxy send connection 17 from local rank 3, transport 0
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected to proxy localRank 3 -> connection 0x7f0080005738
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected to proxy localRank 0 -> connection 0x7fa4a8005738
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6175 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x45c00 fifoLkey=0x45c00
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6176 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x45c00 fifoLkey=0x45c00
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6128 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x41000 fifoLkey=0x41000
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6129 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x41000 fifoLkey=0x41000
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5043 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5044 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6177 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x42600 fifoLkey=0x42600
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6178 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x42600 fifoLkey=0x42600
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6179 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x41200 fifoLkey=0x41200
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6180 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x41200 fifoLkey=0x41200
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6181 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x41c00 fifoLkey=0x41c00
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: NCCL Dev 0 IbDev 0 Port 1 qpn 6182 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/267000AFFFF0000) fifoRkey=0x41c00 fifoLkey=0x41c00
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5014 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5015 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5046 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5047 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6133 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x41f00 fifoLkey=0x41f00
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6134 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x41f00 fifoLkey=0x41f00
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5019 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5020 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5117 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5118 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5090 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5091 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6204 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x42300 fifoLkey=0x42300
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: NCCL Dev 3 IbDev 3 Port 1 qpn 6205 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/26A000AFFFF0000) fifoRkey=0x42300 fifoLkey=0x42300
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5095 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO NET/IB: IbDev 0 Port 1 qpn 5096 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5122 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO NET/IB: IbDev 3 Port 1 qpn 5123 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
pytorch-benchmark-opt-0:108:163 [1] NCCL INFO Connected all rings
pytorch-benchmark-opt-0:110:161 [3] NCCL INFO Connected all rings
pytorch-benchmark-opt-0:109:160 [2] NCCL INFO Connected all rings
pytorch-benchmark-opt-0:107:162 [0] NCCL INFO Connected all rings
    0.10      233.7          189.1          779.7          0.75           0.93           0.22
    0.12      215.2          188.4          907.7          0.98           1.11           0.23
    0.15      225.0          204.5          550.5          1.17           1.28           0.48
    0.20      288.6          206.4         1954.4          1.21           1.70           0.18
    0.32      319.8          268.6         1712.5          1.75           2.08           0.33
    0.40      322.2          254.0         2458.5          2.17           2.76           0.28
    0.50      372.5          275.8         1739.5          2.35           3.17           0.50
    0.64      329.7          283.0         1376.8          3.40           3.96           0.81
    0.80      378.3          279.0         2696.0          3.70           5.02           0.52
    1.00      351.8          258.6         1478.9          4.97           6.77           1.18
    1.25      313.5          280.5          385.3          6.98           7.80           5.68
    1.50      363.3          286.8         2426.6          7.23           9.15           1.08
    2.00      362.9          277.3         1507.7          9.64          12.62           2.32
    3.16      362.3          331.1         1099.4         15.26          16.70           5.03
    4.00      434.1          340.4         2304.8         16.13          20.56           3.04
    5.00      505.8          382.8         2648.7         17.30          22.86           3.30
    6.40      506.7          448.5         1196.2         22.10          24.97           9.36
    8.00      586.7          543.9         1082.2         23.86          25.74          12.94
   10.00      699.5          658.3          772.9         25.02          26.58          22.64
   12.50      849.0          797.1          898.1         25.76          27.44          24.36
   15.00      984.7          933.7         1023.8         26.66          28.11          25.64
   20.00     1370.8         1192.6         3262.5         25.53          29.35          10.73
   31.60     1972.2         1888.7         2151.7         28.04          29.28          25.70
   40.00     2404.7         2225.7         3019.3         29.11          31.45          23.18
   50.00     2934.9         2813.8         3007.8         29.81          31.10          29.09
   64.00     3793.6         3671.2         3892.5         29.52          30.51          28.77
   80.00     4758.1         4669.3         4842.9         29.42          29.98          28.91
  100.00     6352.1         5829.8         8285.1         27.55          30.02          21.12
  125.00     7437.2         7325.9         7629.7         29.41          29.86          28.67
  160.00     9427.8         9298.7         9599.7         29.70          30.11          29.17
  200.00    11783.0        11538.0        12002.9         29.70          30.33          29.16
  250.00    14663.9        14457.9        14945.0         29.84          30.26          29.27
  316.00    18533.0        18282.8        18724.2         29.84          30.25          29.53
  400.00    23404.9        23225.0        23812.1         29.91          30.14          29.40
  500.00    31365.6        28853.9        73205.9         27.90          30.33          11.95
  640.00    37189.4        36775.2        37489.0         30.12          30.46          29.88
  800.00    52759.7        44522.0        112809.5         26.54          31.45          12.41
 1000.00    62076.6        54647.3        97445.0         28.19          32.02          17.96
 1250.00    77466.2        67810.8        113445.1         28.24          32.26          19.28
 1600.00    93571.8        87035.1        104981.8         29.92          32.17          26.67
 2000.00    112784.7        109213.5        114214.7         31.03          32.05          30.64
 2500.00    141937.1        140099.0        147015.4         30.82          31.23          29.76
 3160.00    176490.0        175535.0        177755.6         31.33          31.50          31.11
 4000.00    221045.3        217989.9        223193.6         31.67          32.11          31.36
 5000.00    273713.6        270003.2        276847.7         31.97          32.41          31.61
 6400.00    349458.1        345361.3        355524.6         32.05          32.43          31.50
 8000.00    436657.5        429902.2        444132.2         32.06          32.57          31.52
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:109:154 [2] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:107:158 [0] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:108:152 [1] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:47 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:58 -> 3
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO misc/socket.cc:781 -> 3
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO socketProgressOpt: abort called
pytorch-benchmark-opt-0:110:153 [3] NCCL INFO misc/socket.cc:832 -> 3
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO comm 0x8bb8b90 rank 0 nranks 8 cudaDev 0 busId 6000 - Abort COMPLETE
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO NET/Plugin: Closing net plugin 'IBext_v8'
pytorch-benchmark-opt-0:107:166 [0] NCCL INFO NET/Plugin: Closing collnet plugin 'SHARP'
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO comm 0x8a71100 rank 3 nranks 8 cudaDev 3 busId c6000 - Abort COMPLETE
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO NET/Plugin: Closing net plugin 'IBext_v8'
pytorch-benchmark-opt-0:110:168 [3] NCCL INFO NET/Plugin: Closing collnet plugin 'SHARP'
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO comm 0x9218870 rank 2 nranks 8 cudaDev 2 busId a6000 - Abort COMPLETE
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO NET/Plugin: Closing net plugin 'IBext_v8'
pytorch-benchmark-opt-0:109:167 [2] NCCL INFO NET/Plugin: Closing collnet plugin 'SHARP'
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO comm 0x8bcf130 rank 1 nranks 8 cudaDev 1 busId 26000 - Abort COMPLETE
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO NET/Plugin: Closing net plugin 'IBext_v8'
pytorch-benchmark-opt-0:108:169 [1] NCCL INFO NET/Plugin: Closing collnet plugin 'SHARP'
+ BENCHMARK_EXIT_CODE=0
+ echo '=== Benchmark completed with exit code: 0 ==='
+ '[' 0 -eq 0 ']'
=== Benchmark completed with exit code: 0 ===
SUCCESS: Optimized benchmark completed on pytorch-benchmark-opt-0
Container will remain running. Use 'oc logs' to view results.
+ echo 'SUCCESS: Optimized benchmark completed on pytorch-benchmark-opt-0'
+ echo 'Container will remain running. Use '\''oc logs'\'' to view results.'
+ sleep infinity
